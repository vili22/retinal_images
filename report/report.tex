\documentclass[aps,prb,10pt,twocolumn,groupedaddress]{revtex4-1}
%\setlength\topmargin{4.6mm}
%\documentclass{[prl,twocolumn]{revtex4-1}
%\usepackage[ansinew]{inputenc}
%\usepackage[latin1]{inputenc}% PROPER ENCODINGS
%\usepackage[T1]{fontenc}%      FOR FINNISH TEXT
%\usepackage[finnish]{babel}% 
%\usepackage[official]{eurosym}

%\usepackage{subfig}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{amsmath}
\usepackage{blkarray}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage[font=small,labelfont=bf]{caption}

%\usepackage{subfig}
%\usepackage[footnotesize]{caption}
%\pagestyle{empty}
%\setlength{\textwidth}{140mm}
%\setlength{\textheight}{240mm}
%\setlength{\parindent}{0mm}
%\setlength{\parskip}{3mm plus0.5mm minus0.5mm}
\bibliographystyle{apsrev4-1}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\title{Automatic Detection of Blood Vessels From Retinal Images Using Convolutional Neural Network }
\date{\today}
\author{Ville Virkkala, Jarno Lepp√§nen}
\affiliation{Ekahau Research}

\begin{abstract}
  
\end{abstract}

\maketitle

\section{Introduction}

Several studies have used neural networks in automatic blood vessel detection from retinal images. These methods can be roughly divided into two groups: patch based segmentation of blood vessels and methods based on fully convolutional neural networks. In patch based image segmentation the image is traversed through pixel by pixel. For each pixel a patch of fixed size, centered at the pixel, is taken from the image and fed to neural network that classifies the pixel into certain class.
The advantages of patch based method are their simplicity and ease of training. However, their main disadvantage is the high computational load when doing inference, because for each pixel separate patch is taken that is fed to neural network. Fully convolutional neural network are the current state of the art method in image segmentation. The huge advantage of fully convolutional neural network is the huge speed up compared to patch based methods, because the whole image is fed only once as whole to the neural network. In addition there is more contextual information available in fully convolutional neural networks because the whole image is processed at once instead of using smaller patches. 

In this work patch based semantic segmentation method using convolutional neural network is developed to detect blood vessels from retinal images. The performance of the developed method is validated against several test images. In addition performance of the developed method is compared to random forest classifier implemented in scikit-learn python library.
The paper is organized as follows. The used data-set and the computational
methods are described in detail in sections \ref{sec:used_data_set} and \ref{sec:methods}. In Sec. \ref{sec:results} training metrics and performance of the developed method in inference when applied on test images are given.
Sec. \ref{sec:conclusions} is a summary of the results and the differences between the two classifiers are discussed.

\section{Used data-set}
\label{sec:used_data_set}
The used data set in this work is the publicly available DRIVE data set \cite{drive} available in \cite{drive_url}. The data set consist of 40 images of size 565x584 and the corresponding ground truth annotations of blood vessels. The images were obtained from diabetic subjects as a part of diabetic retinopathy screening program in The Netherlands.

The data set was divided into training, validation and test sets containing 28, 6 and 6 images respectively. The images are three channel RGB images, but only the green channel was used in classification, because typically the blood vessels are best visible at the green channel. In classification of pixels patches of size 33x33 centered at the pixel were used. Examples of retinal image that is classified and the corresponding ground truth image are shown in figures \ref{fig:example_images}a and \ref{fig:example_images}b respectively. Examples of patches that corresponds to pixels that are labeled as blood vessels and background are shown in figures \ref{fig:example_patches}a-\ref{fig:example_patches}c and \ref{fig:example_patches}d-\ref{fig:example_patches}f respectively.
\begin{figure*}[!t]
	\centering
	\begin{subfigure}[]{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/02_training.eps}
		\caption{}
	\end{subfigure}
	\hspace{1cm}
	\centering
	\begin{subfigure}[]{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/02_manual1.eps}
		\caption{}
	\end{subfigure}\\
	\caption{Example of retinal image used in training (a) and the corresponding ground truth annotation of blood vessels (b).}
	\label{fig:example_images}
\end{figure*}

\begin{figure*}[!t]
	\centering
	\begin{subfigure}[]{0.28\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/positive1.eps}
		\caption{}
	\end{subfigure}
	\hspace{0.5cm}
	\centering
	\begin{subfigure}[]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/positive2.eps}
		\caption{}
	\end{subfigure}
	\hspace{0.5cm}
	\centering
	\begin{subfigure}[]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/positive3.eps}
		\caption{}
	\end{subfigure}\\
	\vspace{0.5cm}
	\centering
	\begin{subfigure}[]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/negative1.eps}
		\caption{}
	\end{subfigure}
	\hspace{0.5cm}
	\centering
    \begin{subfigure}[]{0.3\textwidth}
    	\centering
    	\includegraphics[width=\textwidth]{images/negative2.eps}
    	\caption{}
    \end{subfigure}
    \hspace{0.5cm}
    \centering
    \begin{subfigure}[]{0.3\textwidth}
    	\centering
    	\includegraphics[width=\textwidth]{images/negative3.eps}
    	\caption{}
    \end{subfigure}\\
	\caption{Examples of patches corresponding to pixels that are labeled as blood vessels (a)-(c) and patches corresponding to pixels that are labeled as background (d)-(f). The pixel that the label is related to is located at the center of patch.}
	\label{fig:example_patches}
\end{figure*}


\subsection{Computational methods}
\label{sec:computational_methods}
In this work two different methods were used to classify the songs to different
genres. First method is logistic-regression method in which the logistic-loss
is minimized iteratively using the gradient descent method.
The other method used is the Bayes-classifier which classifies the song to
certain category that gives the maximum posterior probability with respect to
label $i$. Both methods are described below in detail. In addition we studied
the effect of feature extraction and for that purpose we used principal
component analysis method to exclude features with little impact. 
\subsubsection{Logistic-regression}

\subsubsection{Principal component analysis}

\begin{center}
  \begin{table}
    \caption{Confusion matrix corresponding to classification obtained using
      logistic regression. The column direction indicates the true value and
      the row direction is the predicted value.  The labels $1\ldots10$ are
      the ten music genres specified in section \ref{sec:used_data_set}.}
    \begin{tabular*}{0.45\textwidth}{@{\extracolsep{\fill}}c|cccccccccc}
        & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
      \hline
      1 & 652 & 35 & 7 & 9 & 4 & 10 & 1 & 3 & 2 & 3\\
      2 & 57 & 130 & 9 & 4 & 2 & 1 & 0 & 2 & 2 & 0\\
      3 & 14 & 9 & 82 & 4 & 2 & 1 & 0 & 0 & 1 & 0 \\
      4 & 25 & 3 & 0 & 43 & 0 & 2 & 0 & 1 & 0 & 2 \\
      5 & 38 & 4 & 1 & 5 & 11 & 1 & 1 & 0 & 3 & 0 \\
      6 & 37 & 6 & 12 & 8 & 4 & 25 & 0 & 0 & 0 & 0 \\
      7 & 34 & 6 & 1 & 2 & 2 & 4 & 3 & 1 & 0 & 0 \\
      8 & 50 & 0 & 0 & 1 & 2 & 1 & 0 & 9 & 0 & 0 \\
      9 & 2 & 5 & 0 & 2 & 1 & 0 & 0 & 8 & 0 & 27 \\
      10 & 21 & 0 & 0 & 6 & 1 & 2 & 0 & 1 & 0 & 3\\
      \end{tabular*}
    \label{tab:confusion_log_reg}
  \end{table}
\end{center}


\section{Conclusions}
\label{sec:conclusions}
In this work we used logistic-regression and Bayes-classifier to classify songs
to different genres based on the music signal's characteristics. For logistic
regression the obtained accuracy for test set was 0.67 and logistic-loss 0.27.
For the external data set used the obtained accuracy and logistic-loss were 0.65
and 0.178 respectively in the case of logistic-regression. For the
Bayes-classifier the obtained accuracy and logistic-loss were 0.53 and 0.33 for
the test-data and for external data set 0.32 and 1.17 respectively. According to
obtained results both classifiers performed clearly better than random guess,
but remained far from perfect classification. From the two classifiers used
the logistic-regression classifier performed clearly better. The logistic
classifier also generalized much better to completely new data giving nearly
equal performance for test data set and external data set.

\bibliography{references}

\end{document} 






